exp:
  dataconfig: /kaggle/working/NeCA/config/config.yml
  # Batch processing configuration
  input_data_dir: /kaggle/input/deepca-preprocessed-dataset/data/split_two  # Directory containing ground truth volumes (1.npy, 2.npy, etc.)
  output_recon_dir: ./logs/reconstructions/  # Directory to save reconstructions (recon_1.npy, etc.)
  model_numbers: [900]  # List of model numbers to train on (corresponds to {number}.npy files)
  current_model_id: 900  # Current model being processed (will be updated automatically)
network:
  net_type: mlp
  num_layers: 8
  hidden_dim: 256
  skips: [4]
  out_dim: 1
  bound: 0.3
  use_gradient_checkpointing: true  # Enable gradient checkpointing for memory efficiency
encoder:
  encoding: hashgrid
  input_dim: 3
  num_levels: 16
  level_dim: 2
  base_resolution: 16
  log2_hashmap_size: 19
render:
  netchunk: 699060
train:
  epoch: 5000
  lrate: [0.0001]  # List of learning rates to experiment with
  mixed_precision: true  # Enable mixed precision training
  weight_decay: 0.000001  # Add weight decay for regularization (1e-6)
  memory_efficient_eval: true  # Use memory-efficient evaluation
  # SDF-related parameters
  use_sdf: true  # Use SDF representation instead of occupancy
  sdf_alpha: 50.0  # Sharpness parameter for SDF to occupancy conversion
  # Loss weight experiments - [projection_weight, sdf_2d_weight]
  loss_weight_experiments: [[0.5, 1.0]]